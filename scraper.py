#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨RSSæŠ“å–è„šæœ¬ - æ¯å¤©æŠ“å–ç§‘æŠ€èµ„è®¯å¹¶ç”ŸæˆJSONæ•°æ®
"""
import sys
import io
import feedparser
import json
import time
import re
from datetime import datetime
from urllib.parse import urlparse
from html import unescape
import hashlib

# ä¿®å¤Windowsæ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open('config.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def generate_id(url):
    """ç”Ÿæˆæ–‡ç« å”¯ä¸€ID"""
    return hashlib.md5(url.encode()).hexdigest()[:12]

def clean_html(text):
    """æ¸…ç†HTMLæ ‡ç­¾ï¼Œåªä¿ç•™çº¯æ–‡æœ¬"""
    if not text:
        return ''

    # è§£ç HTMLå®ä½“ (å¦‚ &amp; &lt; ç­‰)
    text = unescape(text)

    # ç§»é™¤HTMLæ ‡ç­¾
    text = re.sub(r'<[^>]+>', '', text)

    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text)

    # å»é™¤é¦–å°¾ç©ºæ ¼
    text = text.strip()

    return text

def parse_rss_feed(feed_url, feed_name, category, max_articles):
    """è§£æå•ä¸ªRSSæº"""
    print(f"ğŸ“¡ æ­£åœ¨æŠ“å–: {feed_name} ({feed_url})")

    try:
        feed = feedparser.parse(feed_url)
        articles = []

        for entry in feed.entries[:max_articles]:
            # è·å–æè¿°å¹¶æ¸…ç†HTML
            raw_description = entry.get('summary', entry.get('description', ''))
            clean_description = clean_html(raw_description)

            # é™åˆ¶é•¿åº¦
            if len(clean_description) > 200:
                clean_description = clean_description[:200] + '...'

            article = {
                'id': generate_id(entry.link),
                'title': entry.get('title', 'æ— æ ‡é¢˜'),
                'link': entry.get('link', ''),
                'description': clean_description,
                'published': entry.get('published', entry.get('updated', '')),
                'source': feed_name,
                'category': category,
                'timestamp': time.time()
            }
            articles.append(article)

        print(f"âœ… {feed_name}: æˆåŠŸæŠ“å– {len(articles)} ç¯‡æ–‡ç« ")
        return articles

    except Exception as e:
        print(f"âŒ {feed_name}: æŠ“å–å¤±è´¥ - {str(e)}")
        return []

def scrape_all_feeds():
    """æŠ“å–æ‰€æœ‰RSSæº"""
    config = load_config()
    all_articles = []

    print("\n" + "="*60)
    print("ğŸš€ å¼€å§‹è‡ªåŠ¨æŠ“å–ç§‘æŠ€èµ„è®¯...")
    print("="*60 + "\n")

    for feed in config['rss_feeds']:
        articles = parse_rss_feed(
            feed['url'],
            feed['name'],
            feed['category'],
            config.get('max_articles_per_feed', 20)
        )
        all_articles.extend(articles)
        time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«

    # å»é‡ï¼ˆæ ¹æ®IDï¼‰
    seen_ids = set()
    unique_articles = []
    for article in all_articles:
        if article['id'] not in seen_ids:
            seen_ids.add(article['id'])
            unique_articles.append(article)

    # æŒ‰æ—¶é—´æˆ³æ’åº
    unique_articles.sort(key=lambda x: x['timestamp'], reverse=True)

    return unique_articles

def save_data(articles):
    """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
    data = {
        'last_updated': datetime.now().isoformat(),
        'total_articles': len(articles),
        'articles': articles
    }

    with open('public/data.json', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… æ•°æ®å·²ä¿å­˜: {len(articles)} ç¯‡æ–‡ç« ")
    print(f"ğŸ“„ æ–‡ä»¶ä½ç½®: public/data.json")

def main():
    """ä¸»å‡½æ•°"""
    try:
        articles = scrape_all_feeds()
        save_data(articles)

        print("\n" + "="*60)
        print("ğŸ‰ æŠ“å–å®Œæˆï¼")
        print("="*60)
        print(f"æ€»è®¡: {len(articles)} ç¯‡æ–‡ç« ")
        print(f"æ›´æ–°æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {str(e)}")
        raise

if __name__ == '__main__':
    main()
